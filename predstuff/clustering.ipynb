{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge, RANSACRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_measure_reg(df, model, l_col, f_cols, scale_f=False, poly_f=False, picklize=False, save_dir=\"/\"):\n",
    "    \"\"\"\n",
    "    In: df        - DataFrame object that we want to learn from\n",
    "        model     - sklearn ML object\n",
    "        l_col     - label column name\n",
    "        f_cols    - list of feature column names\n",
    "        \n",
    "    Out: tuple of mse and pred-true pairing DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df[f_cols].values\n",
    "    y = df[l_col].tolist()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "    \n",
    "    \n",
    "    if poly_f:\n",
    "        X_train, X_test = _transform(X_train, X_test, PolynomialFeatures())\n",
    "        \n",
    "    if scale_f:\n",
    "        X_train, X_test = _transform(X_train, X_test, StandardScaler())\n",
    "    \n",
    "    reg = model\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    if picklize:\n",
    "        pickle.dump(reg, open(save_dir + \"reg_model.p\", \"wb\"))\n",
    "        \n",
    "    \n",
    "    pred = reg.predict(X_test)\n",
    "    \n",
    "    \n",
    "    pred_df = pd.DataFrame(data = {'pred': pred, 'true': y_test}, columns = ['pred', 'true'])\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    return sqrt(mse), pred_df\n",
    "\n",
    "\n",
    "def train_cl(df, model, f_cols, picklize=False, save_dir=\"/\"):\n",
    "    \"\"\"\n",
    "    In: df        - DataFrame object that we want to learn from\n",
    "        model     - sklearn ML object\n",
    "        l_col     - label column name\n",
    "        f_cols    - list of feature column names\n",
    "    Out: tuple of mse and pred-true pairing DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df[f_cols].values\n",
    "    \n",
    "    cl = model\n",
    "    cl.fit(X)\n",
    "    \n",
    "    if picklize:\n",
    "        pickle.dump(model, open(save_dir + 'cl_model.p', \"wb\"))\n",
    "        \n",
    "    pred = cl.predict(X)\n",
    "\n",
    "    df['pred'] = pred\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def _transform(X_train, X_test, transformer):\n",
    "    tr = transformer.fit(X_train)\n",
    "    \n",
    "    X_train = tr.transform(X_train)\n",
    "    X_test = tr.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test \n",
    "\n",
    "\n",
    "def predict(model, features):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "    reg: sklearn prediction model (pickle file)\n",
    "    features: feature column vector\n",
    "\n",
    "    OUT: float of predicted tax deduction\n",
    "    \"\"\"\n",
    "    preds = model.predict(features)\n",
    "    return preds[0]\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"\n",
    "    Loads pickle model for prediction stuff\n",
    "    \"\"\"\n",
    "    return pickle.load(open(path, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"/Users/yan/Documents/govhack/data/Allyearssamplefile/all_data/2014-15.txt\"\n",
    "df = pd.read_csv(fname, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: dummy variables: Occ_code, Partner_status, Region\n",
    "\n",
    "reg_cols = ['Gender', 'age_range', 'Sw_amt']\n",
    "cl_cols = ['Gender', 'age_range', 'Sw_amt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got regression model with mse = 7490.86494976\n",
      "got clustering model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yan/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/Users/yan/Documents/govhack/Lambda/predstuff/models/\"\n",
    "\n",
    "mse, pred_df = train_test_measure_reg(df=df, \n",
    "                                      model=Ridge(), \n",
    "                                      l_col='Tot_ded_amt', \n",
    "                                      f_cols=reg_cols, \n",
    "                                      scale_f=False, \n",
    "                                      poly_f=False, \n",
    "                                      picklize=True,\n",
    "                                      save_dir=save_dir)\n",
    "\n",
    "print \"got regression model with mse = {}\".format(mse)\n",
    "\n",
    "cl_df = train_cl(df=df, \n",
    "                 model=KMeans(), \n",
    "                 f_cols=cl_cols, \n",
    "                 picklize=True,\n",
    "                 save_dir=save_dir)\n",
    "\n",
    "print \"got clustering model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Getting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_dir = \"/Users/yan/Documents/govhack/Lambda/predstuff/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "reg_model = load_model(models_dir + \"reg_model.p\")\n",
    "print reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=8, n_init=10,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
      "    verbose=0)\n"
     ]
    }
   ],
   "source": [
    "cl_model = load_model(models_dir + \"cl_model.p\")\n",
    "print cl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Processing flow example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5584.41040012\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yan/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/yan/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#'Gender', 'age_range', 'Sw_amt'\n",
    "\n",
    "f_vector_reg = [1, 10, 200000]\n",
    "pred = predict(reg_model, f_vector_reg) # Getting regression prediction\n",
    "print pred\n",
    "\n",
    "f_vector_cl = [1, 10, 200000]\n",
    "cl = predict(cl_model, f_vector_reg)\n",
    "print cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Taking look at the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
