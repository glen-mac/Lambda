{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GovHack\\\\all_data\\\\2003-04.txt', 'D:\\\\GovHack\\\\all_data\\\\2004-05.txt', 'D:\\\\GovHack\\\\all_data\\\\2005-06.txt', 'D:\\\\GovHack\\\\all_data\\\\2008-09.txt', 'D:\\\\GovHack\\\\all_data\\\\2009-10.txt', 'D:\\\\GovHack\\\\all_data\\\\2010-11.txt', 'D:\\\\GovHack\\\\all_data\\\\2011-12.txt', 'D:\\\\GovHack\\\\all_data\\\\2012-13.txt', 'D:\\\\GovHack\\\\all_data\\\\2013-14.txt', 'D:\\\\GovHack\\\\all_data\\\\2014-15.txt', 'D:\\\\GovHack\\\\all_data\\\\wtf.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "path = \"D:\\\\GovHack\\\\all_data\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(path,\"*.txt\"))\n",
    "\n",
    "print all_files\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RANSACRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#linear_model.RANSACRegressor\n",
    "\n",
    "def train_test_measure_reg(df, model, l_col, f_cols, scale_f=False, poly_f=False, picklize=False):\n",
    "    \"\"\"\n",
    "    In: df        - DataFrame object that we want to learn from\n",
    "        model     - sklearn ML object\n",
    "        l_col     - label column name\n",
    "        f_cols    - list of feature column names\n",
    "        \n",
    "    Out: tuple of mse and pred-true pairing DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df[f_cols].values\n",
    "    y = df[l_col].tolist()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "    \n",
    "    \n",
    "    if poly_f:\n",
    "        X_train, X_test = _transform(X_train, X_test, PolynomialFeatures())\n",
    "        \n",
    "    if scale_f:\n",
    "        X_train, X_test = _transform(X_train, X_test, StandardScaler())\n",
    "    \n",
    "    reg = model\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    if picklize:\n",
    "        pickle.dump(reg, open(\"reg_baseline.p\", \"wb\"), protocol=2)\n",
    "        \n",
    "    \n",
    "    pred = reg.predict(X_test)\n",
    "    \n",
    "    \n",
    "    pred_df = pd.DataFrame(data = {'pred': pred, 'true': y_test}, columns = ['pred', 'true'])\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    return sqrt(mse), pred_df\n",
    "\n",
    "\n",
    "def _transform(X_train, X_test, transformer):\n",
    "    tr = transformer.fit(X_train)\n",
    "    \n",
    "    X_train = tr.transform(X_train)\n",
    "    X_test = tr.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test \n",
    "\n",
    "def visualise_preds(data, n=10000, xy_range = False, x_range=(-4, 4), y_range=(-4, 4)):\n",
    "    data = data.sample(n=n)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    if xy_range:\n",
    "        plt.xlim(x_range[0], x_range[1])\n",
    "        plt.ylim(y_range[0], y_range[1])\n",
    "    sns.regplot(x='pred', y='true', data=data, scatter=True)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file_ in all_files:\n",
    "    #print len(df), file_\n",
    "    df = pd.read_csv(file_, index_col=None, header=0)\n",
    "    df_list.append(df)\n",
    "\n",
    "#df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_col_vals = list(df_list[0].columns.values)\n",
    "\n",
    "crap_files = []\n",
    "good_files = []\n",
    "\n",
    "for df in df_list:\n",
    "    #print len(df)\n",
    "    if df_col_vals != list(df.columns.values):\n",
    "        real_df_col_vals = set(df_col_vals)\n",
    "        this_df_col_vals = set(df.columns.values)\n",
    "    \n",
    "        #print \"{len(real_df_col_vals.difference(this_df_col_vals))}\".format(len(real_df_col_vals.difference(this_df_col_vals)))\n",
    "        #print \"{len(real_df_col_vals.difference(this_df_col_vals))}\".format(len(real_df_col_vals.difference(this_df_col_vals)))\n",
    "        #print \"len: {}\\nunion: {}\\n\".format(len(real_df_col_vals.union(this_df_col_vals)), real_df_col_vals.union(this_df_col_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['NPP_loss_claimed', 'Taxed_othr_pnsn_amt', 'Net_rent_amt', 'Marital_status', 'Untaxed_othr_pnsn_amt', 'Othr_pnsn_amt', 'Grs_int_amt', 'PHI_Ind', 'Tot_inc_amt', 'WRE_other_amt', 'Tot_CY_CG_amt', 'Sw_amt', 'Total_PP_BE_amt', 'Gift_amt', 'Region', 'Taxable_Income', 'Net_NPP_BI_amt', 'Other_rent_ded_amt', 'HECS_accum_ind', 'Net_PT_NPP_dsn', 'Alow_ben_amt', 'Ind', 'Total_NPP_BI_amt', 'Lodgment_method', 'Net_CG_amt', 'Aust_govt_pnsn_allw_amt', 'Total_NPP_BE_amt', 'WRE_self_amt', 'Frk_Div_amt', 'Int_Div_ded_amt', 'Occ_code', 'WRE_trvl_amt', 'Other_inc_amt', 'Net_PT_PP_dsn', 'Rep_frng_ben_amt', 'Rent_cap_wks_amt', 'Gender', 'Other_foreign_inc_amt', 'Gross_rent_amt', 'WRE_uniform_amt', 'Total_PP_BI_amt', 'Birth_year', 'Other_Ded_amt', 'Net_PP_BI_amt', 'Tot_ded_amt', 'Non_emp_spr_amt', 'WRE_car_amt', 'Rent_int_ded_amt', 'Med_Exp_TO_amt', 'Cost_tax_affairs_amt', 'PP_loss_claimed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"D:\\\\GovHack\\\\all_data\\\\2014-15.txt\"\n",
    "df_2015 = pd.read_csv(fname, index_col=None, header=0)\n",
    "#df = pd.read_csv(file_, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331.75884055\n"
     ]
    }
   ],
   "source": [
    "#df_2015_filtered = df_2015[cols]\n",
    "\n",
    "#print df_2015.head()\n",
    "\n",
    "fcols = ['Gender', 'age_range', \n",
    "         'Partner_status', 'Region', 'Sw_amt', \n",
    "         'Alow_ben_amt', 'ETP_txbl_amt', \n",
    "         'Grs_int_amt', 'Aust_govt_pnsn_allw_amt',\n",
    "         'Unfranked_Div_amt','Frk_Div_amt',\n",
    "         'Dividends_franking_cr_amt', 'Net_rent_amt',\n",
    "         'Gross_rent_amt', 'Other_rent_ded_amt',\n",
    "         'Rent_int_ded_amt', 'Rent_cap_wks_amt',\n",
    "         'Net_farm_management_amt','Net_PP_BI_amt',\n",
    "         'Net_NPP_BI_amt','Total_PP_BI_amt',\n",
    "         'Total_NPP_BI_amt','Total_PP_BE_amt',\n",
    "         'Total_NPP_BE_amt','Net_CG_amt',\n",
    "         'Tot_CY_CG_amt','Net_PT_PP_dsn',\n",
    "         'Net_PT_NPP_dsn','Taxed_othr_pnsn_amt',\n",
    "         'Untaxed_othr_pnsn_amt','Other_foreign_inc_amt',\n",
    "         'Other_inc_amt', 'Tot_inc_amt']\n",
    "\n",
    "fcols = ['Taxable_Income', 'Sw_amt']\n",
    "\n",
    "\n",
    "\n",
    "extra = 'Occ_code', 'Lodgment_method', 'PHI_Ind'\n",
    "\n",
    "\n",
    "label = 'Tot_ded_amt'\n",
    "model = Ridge()\n",
    "\n",
    "mse, pred_df_base = train_test_measure_reg(df_2015, model, label, fcols, scale_f=False, poly_f=False, picklize=True)\n",
    "print mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualise_preds(pred_df_base, n = 10000, xy_range = False, x_range=(0, 10000), y_range=(0, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "clf2.predict(X[0:1])\n",
    "\n",
    "pickle.dump(favorite_color, open(\"save.p\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
